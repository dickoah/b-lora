{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct 31 09:54:26 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA L4                      On  |   00000000:00:03.0 Off |                    0 |\n",
      "| N/A   50C    P8             17W /   72W |       0MiB /  23034MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "base                     /opt/conda\n",
      "b-lora                *  /opt/conda/envs/b-lora\n",
      "jupyterlab               /opt/conda/envs/jupyterlab\n",
      "langsam                  /opt/conda/envs/langsam\n",
      "pytorch                  /opt/conda/envs/pytorch\n",
      "tensorflow               /opt/conda/envs/tensorflow\n",
      "yolo                     /opt/conda/envs/yolo\n",
      "yolo_app                 /opt/conda/envs/yolo_app\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda info --envs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Image / Dataset and keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL = \"stabilityai/stable-diffusion-xl-base-1.0\" #\"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "INSTANCE_DATA_DIR = \"img/wayfair-multi\"\n",
    "OUTPUT_DIR = \"data/b-lora/wayfair-multi\"\n",
    "INSTANCE_PROMPT = \"A [way1]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch the training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/b-lora/lib/python3.12/site-packages/accelerate/accelerator.py:443: UserWarning: `log_with=tensorboard` was passed but no supported trackers are currently installed.\n",
      "  warnings.warn(f\"`log_with={log_with}` was passed but no supported trackers are currently installed.\")\n",
      "10/31/2024 10:04:16 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: fp16\n",
      "\n",
      "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "{'variance_type', 'clip_sample_range', 'rescale_betas_zero_snr', 'thresholding', 'dynamic_thresholding_ratio'} was not found in config. Values will be initialized to default values.\n",
      "{'latents_mean', 'use_post_quant_conv', 'mid_block_add_attention', 'use_quant_conv', 'shift_factor', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
      "{'attention_type', 'reverse_transformer_layers_per_block', 'dropout'} was not found in config. Values will be initialized to default values.\n",
      "10/31/2024 10:04:28 - INFO - __main__ - ***** Running training *****\n",
      "10/31/2024 10:04:28 - INFO - __main__ -   Num examples = 6\n",
      "10/31/2024 10:04:28 - INFO - __main__ -   Num batches each epoch = 6\n",
      "10/31/2024 10:04:28 - INFO - __main__ -   Num Epochs = 167\n",
      "10/31/2024 10:04:28 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
      "10/31/2024 10:04:28 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "10/31/2024 10:04:28 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
      "10/31/2024 10:04:28 - INFO - __main__ -   Total optimization steps = 1000\n",
      "Steps:   0%|                                           | 0/1000 [00:00<?, ?it/s]/opt/conda/envs/b-lora/lib/python3.12/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
      "Steps:  18%|██          | 175/1000 [06:56<33:13,  2.42s/it, loss=0.299, lr=5e-5]"
     ]
    }
   ],
   "source": [
    "!accelerate launch train_dreambooth_b-lora_sdxl.py \\\n",
    " --pretrained_model_name_or_path=\"$MODEL\" \\\n",
    " --instance_data_dir=\"$INSTANCE_DATA_DIR\" \\\n",
    " --output_dir=\"$OUTPUT_DIR\" \\\n",
    " --instance_prompt=\"$INSTANCE_PROMPT\" \\\n",
    " --resolution=1024 \\\n",
    " --rank=64 \\\n",
    " --train_batch_size=1 \\\n",
    " --learning_rate=5e-5 \\\n",
    " --lr_scheduler=\"constant\" \\\n",
    " --lr_warmup_steps=0 \\\n",
    " --max_train_steps=1000 \\\n",
    " --checkpointing_steps=1001 \\\n",
    " --seed=\"0\" \\\n",
    " --gradient_checkpointing \\\n",
    " --use_8bit_adam \\\n",
    " --mixed_precision=\"fp16\" \\\n",
    " --use_dora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "b-lora",
   "name": "workbench-notebooks.m121",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m121"
  },
  "kernelspec": {
   "display_name": "Python (b-lora) (Local)",
   "language": "python",
   "name": "b-lora"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
