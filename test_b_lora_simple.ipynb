{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Oct 28 14:28:13 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 565.57.02              Driver Version: 566.03         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3080 ...    On  |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   60C    P8             23W /   80W |    1242MiB /  16384MiB |     19%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "base                     /home/dickoah/miniconda3\n",
      "b_lora                *  /home/dickoah/miniconda3/envs/b_lora\n",
      "nfinite_genai            /home/dickoah/miniconda3/envs/nfinite_genai\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda info --envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mblora_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BLOCKS, filter_lora, scale_lora\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdiffusers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      6\u001b[0m     AutoencoderKL, \n\u001b[1;32m      7\u001b[0m     AutoPipelineForText2Image, \n\u001b[1;32m      8\u001b[0m     TCDScheduler\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdiffusers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_image_grid\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from blora_utils import BLOCKS, filter_lora, scale_lora\n",
    "\n",
    "from diffusers import (\n",
    "    AutoencoderKL, \n",
    "    AutoPipelineForText2Image, \n",
    "    TCDScheduler\n",
    ")\n",
    "from diffusers.utils import make_image_grid\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling of the generation the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_b_lora_to_unet(pipe, \n",
    "                        content_lora_model_id: str = '', \n",
    "                        style_lora_model_id: str = '', \n",
    "                        content_alpha: float = 1.,\n",
    "                        style_alpha: float = 1.) -> None:\n",
    "    try:\n",
    "        # Get Content B-LoRA SD\n",
    "        if content_lora_model_id:\n",
    "            content_B_LoRA_sd, _ = pipe.lora_state_dict(content_lora_model_id)\n",
    "            content_B_LoRA = filter_lora(content_B_LoRA_sd, BLOCKS['content'])\n",
    "            content_B_LoRA = scale_lora(content_B_LoRA, content_alpha)\n",
    "        else:\n",
    "            content_B_LoRA = {}\n",
    "\n",
    "        # Get Style B-LoRA SD\n",
    "        if style_lora_model_id:\n",
    "            style_B_LoRA_sd, _ = pipe.lora_state_dict(style_lora_model_id)\n",
    "            style_B_LoRA = filter_lora(style_B_LoRA_sd, BLOCKS['style'])\n",
    "            style_B_LoRA = scale_lora(style_B_LoRA, style_alpha)\n",
    "        else:\n",
    "            style_B_LoRA = {}\n",
    "\n",
    "        # Merge B-LoRAs SD\n",
    "        res_lora = {**content_B_LoRA, **style_B_LoRA}\n",
    "\n",
    "        # Load\n",
    "        pipe.load_lora_into_unet(res_lora, None, pipe.unet)\n",
    "    except Exception as e:\n",
    "        raise type(e)(f'failed to load_b_lora_to_unet, due to: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(\"device:\", device)\n",
    "\n",
    "model_id_or_path = \"SG161222/RealVisXL_V5.0_Lightning\" #\"SG161222/RealVisXL_V5.0_Lightning\" #stabilityai/stable-diffusion-xl-base-1.0 #\n",
    "vae_id_or_path = \"madebyollin/sdxl-vae-fp16-fix\"\n",
    "\n",
    "vae = AutoencoderKL.from_pretrained(vae_id_or_path, torch_dtype=torch.float16)\n",
    "\n",
    "pipe_tex2img = AutoPipelineForText2Image.from_pretrained(model_id_or_path,\n",
    "                                                              vae=vae,\n",
    "                                                              torch_dtype=torch.float16,\n",
    "                                                            )              \n",
    "\n",
    "# Setting up of others parameters\n",
    "pipe_tex2img.enable_xformers_memory_efficient_attention()\n",
    "pipe_tex2img = pipe_tex2img.to(device)\n",
    "\n",
    "# Update of the scheduler\n",
    "pipe_tex2img.scheduler = TCDScheduler.from_config(pipe_tex2img.scheduler.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_B_LoRA_path = \"\"\n",
    "style_B_LoRA_path = \"data/b-lora/Dordogne/pytorch_lora_weights.safetensors\"\n",
    "content_alpha, style_alpha = 1, 1.1\n",
    "lora_trigger_word = \"[dordogne]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_b_lora_to_unet(pipe_tex2img, content_B_LoRA_path, style_B_LoRA_path, content_alpha, style_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42 # torch.randint(0, 1000000, (1,)).item()\n",
    "generator = torch.Generator(device=device).manual_seed(seed)\n",
    "print(f\"seed: {seed}\")\n",
    "\n",
    "# batch size\n",
    "N = 1\n",
    "steps = 10\n",
    "guidance_scale=1.7\n",
    "\n",
    "# prompt instanciation\n",
    "prompt = f'The image shows a chair in a living room in style {lora_trigger_word} with a very large rug on the floor, windows, a cupboard with books and a photo frame on top, a window with a curtain, and a wall in the background, plant in pot, painting on wall, stright-lines.'\n",
    "print(\"prompt: \", prompt)\n",
    "\n",
    "# creation of the image(s)\n",
    "images_output = pipe_tex2img(prompt=prompt, \n",
    "                                  negative_prompt=None,\n",
    "                                  num_inference_steps=steps,\n",
    "                                  num_images_per_prompt=N,\n",
    "                                  guidance_scale=guidance_scale,\n",
    "                                  generator=generator).images\n",
    "\n",
    "# save of the image\n",
    "images_output[0].save(f'blora_result_without_negative_prompt.png', \"PNG\")\n",
    "\n",
    "make_image_grid(images_output, rows=1, cols=N, resize=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation of the image(s)\n",
    "images_output = pipe_tex2img(prompt=prompt, \n",
    "                                  negative_prompt=\"\",\n",
    "                                  num_inference_steps=steps,\n",
    "                                  num_images_per_prompt=N,\n",
    "                                  guidance_scale=guidance_scale,\n",
    "                                  generator=generator).images\n",
    "\n",
    "images_output[0].save(f'blora_result_with_empty_negative_prompt.png', \"PNG\")\n",
    "\n",
    "make_image_grid(images_output, rows=1, cols=N, resize=512)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "b_lora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
